{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.io.matlab import loadmat\n",
    "from nilearn import plotting\n",
    "from nilearn import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/remi/data/AV_att/'\n",
    "dropbox_path = '/home/remi/Dropbox/PhD/Experiments/AV_Integration_7T/Subjects_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_names = [\n",
    "    ' A Stim - Auditory Attention',\n",
    "    ' V Stim - Auditory Attention',\n",
    "    ' AV Stim - Auditory Attention',\n",
    "    ' A Stim - Visual Attention',\n",
    "    ' V Stim - Visual Attention',\n",
    "    ' AV Stim - Visual Attention']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_ls = glob.glob(os.path.join(data_path, 'sub*'), recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "09\n",
      "08\n",
      "03\n",
      "02\n",
      "11\n",
      "15\n",
      "13\n",
      "07\n",
      "04\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for i_subj in subj_ls:\n",
    "    \n",
    "    subj = i_subj.split('/')[-1]\n",
    "    \n",
    "    print(subj[4:])\n",
    "    \n",
    "    # open the SPM.mat and look for the name of the regressors\n",
    "    SPM_mat = os.path.join(dropbox_path, 'Subject_' + subj[4:], 'FFX_Block', 'SPM.mat')\n",
    "    SPM_mat = loadmat(SPM_mat, struct_as_record=True)\n",
    "    \n",
    "    SPM_xX = SPM_mat['SPM'][0][0][7] # that would be SPM.xX (I think)\n",
    "    reg_names = SPM_xX[0][0][6][0] # that should be all the regressor names\n",
    "    \n",
    "    nb_reg = reg_names.size\n",
    "    \n",
    "    cdt_vec = []\n",
    "    \n",
    "    # we loop through all the regressor names and check to which condition each belong\n",
    "    for i_reg in range(nb_reg):\n",
    "\n",
    "        reg = reg_names[i_reg][0] # extract the string from the array\n",
    "\n",
    "        cdt_vec.append(-1); # dummy values to ignore this regressor in case it is not waht we want\n",
    "\n",
    "        # we loop through the condition names and check that we have a match \n",
    "        # (also with bf(1) to make sure it is the HRF contrast)\n",
    "        for i_cdt in range(len(conditions_names)):\n",
    "            # if there is match we give that regressor the number of the condition\n",
    "            if reg.find(conditions_names[i_cdt]) != -1 and reg.find('bf(1)') != -1:\n",
    "                cdt_vec[i_reg] = i_cdt \n",
    "                break\n",
    "    \n",
    "    \n",
    "    for i_cdt in range(len(conditions_names)):\n",
    "        # find indices of beta images that correspond to each condition\n",
    "        ind_list = [i for i, value in enumerate(cdt_vec) if value == i_cdt] \n",
    "        \n",
    "        beta_img = []\n",
    "        \n",
    "        for i_beta in ind_list:\n",
    "            file_name = \"r4beta_{0:04d}.nii.gz\".format(i_beta + 1)\n",
    "            beta_img.append( os.path.join(i_subj, 'Betamapping', file_name) )\n",
    "            \n",
    "            #exists = os.path.isfile(beta_img)\n",
    "            #if exists:\n",
    "            \n",
    "            #beta_img_hdr = nib.load(beta_img)\n",
    "            #beta_img_data = beta_img_hdr.get_fdata()\n",
    "            \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = '/home/remi/Dropbox/PhD/Experiments/AV_Integration_7T/ROI/ret_proba_atlas/maxprob_vol_lh.nii.gz'\n",
    "\n",
    "plotting.plot_glass_brain(ROI)   \n",
    "#plotting.plot_stat_map(ROI)\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = image.load_img(beta_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = data.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-20830b5d67fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first create a masker, giving it the options that we care\n",
    "# about. Here we use standardizing of the data, as it is often important\n",
    "# for decoding\n",
    "from nilearn.input_data import NiftiMasker\n",
    "#masker = NiftiMasker(mask_img=mask_filename, standardize=True)\n",
    "\n",
    "# We give the masker a filename and retrieve a 2D array ready\n",
    "# for machine learning with scikit-learn\n",
    "#fmri_masked = masker.fit_transform(fmri_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NiftiMasker in module nilearn.input_data.nifti_masker:\n",
      "\n",
      "class NiftiMasker(nilearn.input_data.base_masker.BaseMasker, nilearn._utils.cache_mixin.CacheMixin)\n",
      " |  NiftiMasker(mask_img=None, sessions=None, smoothing_fwhm=None, standardize=False, detrend=False, low_pass=None, high_pass=None, t_r=None, target_affine=None, target_shape=None, mask_strategy='background', mask_args=None, sample_mask=None, dtype=None, memory_level=1, memory=Memory(location=None), verbose=0)\n",
      " |  \n",
      " |  Applying a mask to extract time-series from Niimg-like objects.\n",
      " |  \n",
      " |  NiftiMasker is useful when preprocessing (detrending, standardization,\n",
      " |  resampling, etc.) of in-mask voxels is necessary. Use case: working with\n",
      " |  time series of resting-state or task maps.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  mask_img : Niimg-like object, optional\n",
      " |      See http://nilearn.github.io/manipulating_images/input_output.html\n",
      " |      Mask for the data. If not given, a mask is computed in the fit step.\n",
      " |      Optional parameters (mask_args and mask_strategy) can be set to\n",
      " |      fine tune the mask extraction.\n",
      " |  \n",
      " |  sessions : numpy array, optional\n",
      " |      Add a session level to the preprocessing. Each session will be\n",
      " |      detrended independently. Must be a 1D array of n_samples elements.\n",
      " |  \n",
      " |  smoothing_fwhm : float, optional\n",
      " |      If smoothing_fwhm is not None, it gives the full-width half maximum in\n",
      " |      millimeters of the spatial smoothing to apply to the signal.\n",
      " |  \n",
      " |  standardize : boolean, optional\n",
      " |      If standardize is True, the time-series are centered and normed:\n",
      " |      their mean is put to 0 and their variance to 1 in the time dimension.\n",
      " |  \n",
      " |  detrend : boolean, optional\n",
      " |      This parameter is passed to signal.clean. Please see the related\n",
      " |      documentation for details\n",
      " |  \n",
      " |  low_pass: None or float, optional\n",
      " |      This parameter is passed to signal.clean. Please see the related\n",
      " |      documentation for details\n",
      " |  \n",
      " |  high_pass: None or float, optional\n",
      " |      This parameter is passed to signal.clean. Please see the related\n",
      " |      documentation for details\n",
      " |  \n",
      " |  t_r : float, optional\n",
      " |      This parameter is passed to signal.clean. Please see the related\n",
      " |      documentation for details\n",
      " |  \n",
      " |  target_affine : 3x3 or 4x4 matrix, optional\n",
      " |      This parameter is passed to image.resample_img. Please see the\n",
      " |      related documentation for details.\n",
      " |  \n",
      " |  target_shape : 3-tuple of integers, optional\n",
      " |      This parameter is passed to image.resample_img. Please see the\n",
      " |      related documentation for details.\n",
      " |  \n",
      " |  mask_strategy: {'background', 'epi' or 'template'}, optional\n",
      " |      The strategy used to compute the mask: use 'background' if your\n",
      " |      images present a clear homogeneous background, 'epi' if they\n",
      " |      are raw EPI images, or you could use 'template' which will\n",
      " |      extract the gray matter part of your data by resampling the MNI152\n",
      " |      brain mask for your data's field of view.\n",
      " |      Depending on this value, the mask will be computed from\n",
      " |      masking.compute_background_mask, masking.compute_epi_mask or\n",
      " |      masking.compute_gray_matter_mask. Default is 'background'.\n",
      " |  \n",
      " |  mask_args : dict, optional\n",
      " |      If mask is None, these are additional parameters passed to\n",
      " |      masking.compute_background_mask or masking.compute_epi_mask\n",
      " |      to fine-tune mask computation. Please see the related documentation\n",
      " |      for details.\n",
      " |  \n",
      " |  sample_mask : Any type compatible with numpy-array indexing\n",
      " |      Masks the niimgs along time/fourth dimension. This complements\n",
      " |      3D masking by the mask_img argument. This masking step is applied\n",
      " |      before data preprocessing at the beginning of NiftiMasker.transform.\n",
      " |      This is useful to perform data subselection as part of a scikit-learn\n",
      " |      pipeline.\n",
      " |  \n",
      " |  `dtype: {dtype, \"auto\"}\n",
      " |      Data type toward which the data should be converted. If \"auto\", the\n",
      " |      data will be converted to int32 if dtype is discrete and float32 if it\n",
      " |      is continuous.\n",
      " |  \n",
      " |  memory : instance of joblib.Memory or string\n",
      " |      Used to cache the masking process.\n",
      " |      By default, no caching is done. If a string is given, it is the\n",
      " |      path to the caching directory.\n",
      " |  \n",
      " |  memory_level : integer, optional\n",
      " |      Rough estimator of the amount of memory used by caching. Higher value\n",
      " |      means more memory for caching.\n",
      " |  \n",
      " |  verbose : integer, optional\n",
      " |      Indicate the level of verbosity. By default, nothing is printed\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  `mask_img_` : nibabel.Nifti1Image\n",
      " |      The mask of the data, or the computed one.\n",
      " |  \n",
      " |  `affine_` : 4x4 numpy array\n",
      " |      Affine of the transformed image.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  nilearn.masking.compute_background_mask\n",
      " |  nilearn.masking.compute_epi_mask\n",
      " |  nilearn.image.resample_img\n",
      " |  nilearn.masking.apply_mask\n",
      " |  nilearn.signal.clean\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NiftiMasker\n",
      " |      nilearn.input_data.base_masker.BaseMasker\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      nilearn._utils.cache_mixin.CacheMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, mask_img=None, sessions=None, smoothing_fwhm=None, standardize=False, detrend=False, low_pass=None, high_pass=None, t_r=None, target_affine=None, target_shape=None, mask_strategy='background', mask_args=None, sample_mask=None, dtype=None, memory_level=1, memory=Memory(location=None), verbose=0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, imgs=None, y=None)\n",
      " |      Compute the mask corresponding to the data\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      imgs: list of Niimg-like objects\n",
      " |          See http://nilearn.github.io/manipulating_images/input_output.html\n",
      " |          Data on which the mask must be calculated. If this is a list,\n",
      " |          the affine is considered the same for all.\n",
      " |  \n",
      " |  transform_single_imgs(self, imgs, confounds=None, copy=True)\n",
      " |      Apply mask, spatial and temporal preprocessing\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      imgs: 3D/4D Niimg-like object\n",
      " |          See http://nilearn.github.io/manipulating_images/input_output.html\n",
      " |          Images to process. It must boil down to a 4D image with scans\n",
      " |          number as last dimension.\n",
      " |      \n",
      " |      confounds: CSV file or array-like, optional\n",
      " |          This parameter is passed to signal.clean. Please see the related\n",
      " |          documentation for details.\n",
      " |          shape: (number of scans, number of confounds)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      region_signals: 2D numpy.ndarray\n",
      " |          Signal for each voxel inside the mask.\n",
      " |          shape: (number of scans, number of voxels)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nilearn.input_data.base_masker.BaseMasker:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, confounds=None, **fit_params)\n",
      " |      Fit to data, then transform it\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : Niimg-like object\n",
      " |          See http://nilearn.github.io/manipulating_images/input_output.html\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      confounds: list of confounds, optional\n",
      " |          List of confounds (2D arrays or filenames pointing to CSV\n",
      " |          files). Must be of same length than imgs_list.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Transform the 2D data matrix back to an image in brain space.\n",
      " |  \n",
      " |  transform(self, imgs, confounds=None)\n",
      " |      Apply mask, spatial and temporal preprocessing\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      imgs: 3D/4D Niimg-like object\n",
      " |          See http://nilearn.github.io/manipulating_images/input_output.html\n",
      " |          Images to process. It must boil down to a 4D image with scans\n",
      " |          number as last dimension.\n",
      " |      \n",
      " |      confounds: CSV file or array-like, optional\n",
      " |          This parameter is passed to signal.clean. Please see the related\n",
      " |          documentation for details.\n",
      " |          shape: (number of scans, number of confounds)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      region_signals: 2D numpy.ndarray\n",
      " |          Signal for each element.\n",
      " |          shape: (number of scans, number of elements)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(NiftiMasker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
